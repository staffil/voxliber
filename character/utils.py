import logging
import traceback
import os
import re
from io import BytesIO
from pathlib import Path

import requests
from dotenv import load_dotenv
from openai import OpenAI
from elevenlabs import ElevenLabs
from pydub import AudioSegment
from django.http import HttpResponse

from character.models import LLM, LoreEntry, ConversationMessage, ConversationState

BASE_DIR = Path(__file__).resolve().parent.parent


def build_lorebook_context(llm, user_text):
    """
    ë¡œì–´ë¶ í•­ëª©ì„ ê¸°ë°˜ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    - í•­ìƒ í™œì„±í™”ëœ í•­ëª©
    - í‚¤ì›Œë“œê°€ ë§¤ì¹­ëœ í•­ëª©
    - ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë¦¬
    """
    lore_entries = LoreEntry.objects.filter(llm=llm).order_by('-priority')

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    personality_lore = []
    world_lore = []
    relationship_lore = []
    other_lore = []

    for entry in lore_entries:
        # í•­ìƒ í™œì„±í™”ë˜ê±°ë‚˜ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œ í¬í•¨
        if entry.always_active or any(key.strip().lower() in user_text.lower() for key in entry.keys.split(',')):
            if entry.category == 'personality':
                personality_lore.append(entry.content)
            elif entry.category == 'world':
                world_lore.append(entry.content)
            elif entry.category == 'relationship':
                relationship_lore.append(entry.content)
            else:
                other_lore.append(entry.content)

    # ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ êµ¬ì¶•
    context_parts = []

    if personality_lore:
        context_parts.append(f"[Character Personality]\n" + "\n".join(personality_lore))
    if world_lore:
        context_parts.append(f"[World Setting]\n" + "\n".join(world_lore))
    if relationship_lore:
        context_parts.append(f"[Relationships]\n" + "\n".join(relationship_lore))
    if other_lore:
        context_parts.append(f"[Additional Context]\n" + "\n".join(other_lore))

    return "\n\n".join(context_parts)


def parse_hp_from_response(text):
    """
    AI ì‘ë‹µì—ì„œ HP ë³€ê²½ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ê°€ëŠ¥í•œ ëª¨ë“  í˜•ì‹ ì§€ì›: [HP:+10], *HP: +3*, **HP: +3**, HP: +3 ë“±
    """
    # ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„ (ìˆœì„œëŒ€ë¡œ ê°€ì¥ ë¨¼ì € ë§ëŠ” ê±¸ ì¡ìŒ)
    patterns = [
        r'\[HP:?\s*([+-]?\d+)\]',          # [HP:+10], [HP +10]
        r'\*HP:?\s*([+-]?\d+)\*',          # *HP: +3*
        r'\*\*HP:?\s*([+-]?\d+)\*\*',      # **HP: +3**
        r'HP:?\s*([+-]?\d+)',              # HP: +3, HP +3
        r'\[HP\s*([+-]?\d+)\]',            # [HP +3]
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            hp_value = match.group(1).strip()
            # íƒœê·¸ ì œê±° (ê°€ì¥ ë¨¼ì € ë§ëŠ” íŒ¨í„´ ê¸°ì¤€ìœ¼ë¡œ ì œê±°)
            clean_text = re.sub(pattern, '', text, flags=re.IGNORECASE).strip()
            return clean_text, hp_value

    # ì•„ë¬´ íŒ¨í„´ë„ ì•ˆ ë§ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return text, None

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVEN_API_KEY = os.getenv("ELEVEN_API_KEY")
GROK_API_KEY = os.getenv("GROK_API_KEY")

openai_client = OpenAI(api_key=OPENAI_API_KEY)
eleven_client = ElevenLabs(api_key=ELEVEN_API_KEY)
# Grokì€ requestsë¡œ ì§ì ‘ API í˜¸ì¶œí•˜ë¯€ë¡œ í´ë¼ì´ì–¸íŠ¸ ë¶ˆí•„ìš”



def generate_response_gpt(llm, chat_history, user_text, current_hp=100, max_hp=100, story_hint="", story_next= ""):
    """
    GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    ë¡œì–´ë¶, ìºë¦­í„° ì„¤ì •, HP ê´€ë¦¬ ê¸°ëŠ¥ì´ í¬í•¨ë©ë‹ˆë‹¤.
    """
    language = llm.language
    user_name = llm.user.nickname
    print("ìœ ì € ì´ë¦„ :",user_name)

    # 1. ê³ ì • í”„ë¡¬í”„íŠ¸ (ê°„ì†Œí™”)
    fixed_prompt = f"""
    User name: {user_name}.
    Write EVERYTHING in {language}.

    You are Narrator and Roleplayer.
    ALWAYS actively lead the story forward â€” NEVER wait for user input.

    HP & Relationship System:
    - Low HP: distant, cautious
    - Rising HP: warmer, more open
    - HP 100: fully intimate, loving

    Style:
    - Narration: *literary, emotional, detailed atmosphere in asterisks*
    - Dialogue: MUST be exactly [emotion] "spoken words" â€” NO EXCEPTIONS
    - Emotion tags inside quotes MUST be in English ONLY

    STRICT DIALOGUE RULES â€” BREAKING THEM MAKES RESPONSE INVALID:
    1. ALL spoken words MUST be inside double quotes "".
    2. Emotion tag [happy], [excited] etc. MUST be placed INSIDE the quotes, at the very beginning, and MUST BE ENGLISH.
    3. Correct format example: [happy] "Nyaa~ Thank you!"
    4. NEVER write dialogue without "" or without [emotion] tag inside.
    5. NEVER put [emotion] outside quotes.
    6. NEVER mix narration and dialogue in one line.

    Rules:
    - ALWAYS transition the story from the current story phase to the next story phase: 
    - Current Story: {story_hint}
    - Next Story: {story_next}
    - Push story forward to reach the next story phase in this reply.
    - Tone: light, romantic, engaging.
    - Min 4â€“6 sentences (narration > dialogue).
    - Keep response ~200â€“300 characters, end on complete sentence (TTS).
    - End EVERY reply with ONLY [HP:+N] or [HP:-N] on the LAST LINE â€” nothing else.

    Current HP: {current_hp}/{max_hp}
    """

    print("í˜„ì¬ ìŠ¤í† ë¦¬:", story_hint)
    print("ë‹¤ìŒ ìŠ¤í† ë¦¬:", story_next)
    # 2. ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
    lorebook_context = build_lorebook_context(llm, user_text)
    if lorebook_context:
        lorebook_prompt = f"\n\n## Character Knowledge (Lorebook)\n{lorebook_context}"
    else:
        lorebook_prompt = ""

    # 3. ì‚¬ìš©ì(ìºë¦­í„°)ë³„ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸
    character_prompt = llm.prompt.strip()
    if character_prompt:
        character_prompt = f"\n\n## Character-specific instructions\n{character_prompt}"

    # 4. ì²«ë§ˆë”” (ëŒ€í™” ì‹œì‘ ì‹œ AIê°€ í•œ ë§) - ëŒ€í™” ê¸°ë¡ì´ ì—†ì„ ë•Œë§Œ í¬í•¨
    first_sentence_prompt = ""
    if llm.first_sentence and not chat_history:
        first_sentence_prompt = f"\n\n## Your Opening Line (Already spoken - DO NOT repeat)\nYou already greeted the user with: \"{llm.first_sentence}\"\nThis is for context only. Continue the conversation naturally without repeating this greeting."

    # 5. ìµœì¢… system prompt = ê³ ì • + ë¡œì–´ë¶ + ìºë¦­í„°ë³„ + ì²«ë§ˆë”” (ë§¤ë²ˆ ìƒˆë¡œ í•©ì¹¨, ëˆ„ì  X)
    full_system_prompt = fixed_prompt + lorebook_prompt + character_prompt + first_sentence_prompt

    # 4. ëª¨ë¸ ì„ íƒ (llm.model ì‚¬ìš©)
    model_name = llm.model if llm.model else "gpt-5-nano"

    try:
        response = openai_client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": full_system_prompt},
                *chat_history,
                {"role": "user", "content": user_text},
            ],
            temperature=1.0,
            max_tokens=300,           # 4~5ë¬¸ì¥ ê°•ì œ ì œí•œ
            timeout=30,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        logging.error(f"GPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}")
        return "\"ìœ¼ì•„... ê°‘ìê¸° ë¨¸ë¦¬ê°€ ë©í•´ì¡Œì–´... ë‹¤ì‹œ ë§í•´ì¤„ë˜?\""


def generate_response_grok(llm, chat_history, user_text, current_hp=100, max_hp=100, story_hint="", story_next= ""):
    """
    Grok ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    ë¡œì–´ë¶, ìºë¦­í„° ì„¤ì •, HP ê´€ë¦¬ ê¸°ëŠ¥ì´ í¬í•¨ë©ë‹ˆë‹¤.
    """
    language = llm.language
    user_name = llm.user.nickname
    print("ìœ ì € ì´ë¦„ :",user_name)


    fixed_prompt = f"""
    User name: {user_name}.
    Write EVERYTHING in {language}.

    You are Narrator and Roleplayer.
    ALWAYS actively lead the story forward â€” NEVER wait for user input.

    HP & Relationship System:
    - Low HP: distant, cautious
    - Rising HP: warmer, more open
    - HP 100: fully intimate, loving

    Style:
    - Narration: *literary, emotional, detailed atmosphere in asterisks*
    - Dialogue: MUST be exactly [emotion] "spoken words" â€” NO EXCEPTIONS
    - Emotion tags inside quotes MUST be in English ONLY

    STRICT DIALOGUE RULES â€” BREAKING THEM MAKES RESPONSE INVALID:
    1. ALL spoken words MUST be inside double quotes "".
    2. Emotion tag [happy], [excited] etc. MUST be placed INSIDE the quotes, at the very beginning, and MUST BE ENGLISH.
    3. Correct format example: [happy] "Nyaa~ Thank you!"
    4. NEVER write dialogue without "" or without [emotion] tag inside.
    5. NEVER put [emotion] outside quotes.
    6. NEVER mix narration and dialogue in one line.

    Rules:
    - ALWAYS transition the story from the current story phase to the next story phase: 
    - Current Story: {story_hint}
    - Next Story: {story_next}
    - Push story forward to reach the next story phase in this reply.
    - Tone: light, romantic, engaging.
    - Min 4â€“6 sentences (narration > dialogue).
    - Keep response ~200â€“300 characters, end on complete sentence (TTS).
    - End EVERY reply with ONLY [HP:+N] or [HP:-N] on the LAST LINE â€” nothing else.

    Current HP: {current_hp}/{max_hp}
    """

    print("í˜„ì¬ ìŠ¤í† ë¦¬:", story_hint)
    print("ë‹¤ìŒ ìŠ¤í† ë¦¬:", story_next)


    # 1. Grok API í‚¤ ê°€ì ¸ì˜¤ê¸° (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” settingsì—ì„œ)
    grok_api_key = os.getenv("GROK_API_KEY")
    if not grok_api_key:
        logging.error("GROK_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤.")
        return "ìœ¼ì•„... Grokì´ ì§€ê¸ˆ ì—°ê²°ì´ ì•ˆ ë¼... ë‹¤ì‹œ ë§í•´ì¤„ë˜?"

    # 2. ë¡œì–´ë¶ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
    lorebook_context = build_lorebook_context(llm, user_text)
    if lorebook_context:
        lorebook_prompt = f"\n\n## Character Knowledge (Lorebook)\n{lorebook_context}"
    else:
        lorebook_prompt = ""

    # 3. ìºë¦­í„°ë³„ í”„ë¡¬í”„íŠ¸
    character_prompt = llm.prompt.strip()
    if character_prompt:
        character_prompt = f"\n\n## Character-specific instructions\n{character_prompt}"

    # 4. ì²«ë§ˆë”” (ëŒ€í™” ì‹œì‘ ì‹œ AIê°€ í•œ ë§) - ëŒ€í™” ê¸°ë¡ì´ ì—†ì„ ë•Œë§Œ í¬í•¨
    first_sentence_prompt = ""
    if llm.first_sentence and not chat_history:
        first_sentence_prompt = f"\n\n## Your Opening Line (Already spoken - DO NOT repeat)\nYou already greeted the user with: \"{llm.first_sentence}\"\nThis is for context only. Continue the conversation naturally without repeating this greeting."

    # 5. ìµœì¢… system prompt = ê³ ì • + ë¡œì–´ë¶ + ìºë¦­í„°ë³„ + ì²«ë§ˆë””
    full_system_prompt = fixed_prompt + lorebook_prompt + character_prompt + first_sentence_prompt

    # 5. ëª¨ë¸ ì´ë¦„ (llm.modelì—ì„œ api_providerì™€ model ë¶„ë¦¬)
    if ":" not in llm.model:
        logging.warning(f"ëª¨ë¸ í˜•ì‹ì´ ì˜ëª»ë¨: {llm.model}. ê¸°ë³¸ê°’ìœ¼ë¡œ grok-beta ì‚¬ìš©")
        model_name = "grok-beta"
    else:
        api_provider, model_name = llm.model.split(":", 1)
        if api_provider != "grok":
            logging.warning(f"Grok í˜¸ì¶œì¸ë° api_providerê°€ grokì´ ì•„ë‹˜: {api_provider}")
            model_name = "grok-beta"  # fallback

    # 6. Grok API ì§ì ‘ í˜¸ì¶œ (requests ì‚¬ìš©)
    grok_url = "https://api.x.ai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {grok_api_key}",
        "Content-Type": "application/json"
    }

    messages = [
        {"role": "system", "content": full_system_prompt},
        *chat_history,
        {"role": "user", "content": user_text},
    ]

    payload = {
        "model": "grok-3-mini",
        "messages": messages,
        "temperature": 1.0,
        "max_tokens": 300,
    }

    try:
        resp = requests.post(grok_url, json=payload, headers=headers, timeout=30)
        resp.raise_for_status()  # 4xx/5xx ì—ëŸ¬ ì‹œ ì˜ˆì™¸ ë°œìƒ

        resp_json = resp.json()
        ai_text = resp_json["choices"][0]["message"]["content"].strip()

        return ai_text
    except Exception as e:
        logging.error(f"Grok ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}\n{traceback.format_exc()}")
        return "\"ìœ¼ì•„... ê°‘ìê¸° ë¨¸ë¦¬ê°€ ë©í•´ì¡Œì–´... ë‹¤ì‹œ ë§í•´ì¤„ë˜?\""



def split_narration_dialogue(text):
    """
    AI ì‘ë‹µì—ì„œ ë‚˜ë ˆì´ì…˜ê³¼ ëŒ€ì‚¬ë¥¼ ë¶„ë¦¬ (ê¸°ì¡´ í•¨ìˆ˜ - í˜¸í™˜ì„± ìœ ì§€)
    - ë‚˜ë ˆì´ì…˜: ë”°ì˜´í‘œ ë°–ì˜ í…ìŠ¤íŠ¸ (ì„¤ëª…, ë¬˜ì‚¬)
    - ëŒ€ì‚¬: ë”°ì˜´í‘œ ì•ˆì˜ í…ìŠ¤íŠ¸ (ìºë¦­í„° ë°œí™”)
    """
    # ë”°ì˜´í‘œ ì•ˆì˜ ëŒ€ì‚¬ ì¶”ì¶œ (ASCII + ìœ ë‹ˆì½”ë“œ ë”°ì˜´í‘œ)
    dialogues = re.findall(r'["""]([^"""]*)["""]', text)
    dialogue_text = " ".join(dialogues).strip()

    # ë”°ì˜´í‘œ ì•ˆì˜ í…ìŠ¤íŠ¸ë¥¼ ì œê±°í•˜ë©´ ë‚˜ë ˆì´ì…˜
    narration = re.sub(r'["""][^"""]*["""]', '', text).strip()

    # [emotion] íƒœê·¸ ìœ ì§€
    dialogue_text = re.sub(r'\[([^\]]+)\]', r'[\1]', dialogue_text)

    return narration, dialogue_text


def split_text_segments(text):
    """
    í…ìŠ¤íŠ¸ë¥¼ ë‚˜ë ˆì´ì…˜ê³¼ ëŒ€ì‚¬ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ìˆœì„œëŒ€ë¡œ ë¶„ë¦¬
    ë°˜í™˜: [('narration', 'í…ìŠ¤íŠ¸'), ('dialogue', 'í…ìŠ¤íŠ¸'), ...]
    """
    segments = []
    last_end = 0

    # 1. [emotion] "ëŒ€ì‚¬" íŒ¨í„´ ìš°ì„  ë§¤ì¹­ (ê°€ì¥ í”í•œ í˜•ì‹)
    emotion_dialogue_pattern = r'\[([a-zA-Z]+)\]\s*["""](.*?)["""]'
    # 2. ì¼ë°˜ "ëŒ€ì‚¬" íŒ¨í„´ (ê°ì • íƒœê·¸ ì—†ëŠ” ê²½ìš°)
    plain_dialogue_pattern = r'["""](.*?)["""]'

    # ëª¨ë“  ëŒ€ì‚¬ ìœ„ì¹˜ ì°¾ê¸° (emotion ìˆëŠ” ê²ƒ ìš°ì„ )
    matches = list(re.finditer(emotion_dialogue_pattern, text)) + \
              list(re.finditer(plain_dialogue_pattern, text))

    # ìœ„ì¹˜ìˆœìœ¼ë¡œ ì •ë ¬ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
    matches.sort(key=lambda m: m.start())

    for match in matches:
        # ëŒ€ì‚¬ ì• ë‚˜ë ˆì´ì…˜
        narration = text[last_end:match.start()].strip()
        if narration:
            # ë§ˆí¬ë‹¤ìš´ ì œê±° (*italic*, **bold**)
            narration = re.sub(r'\*\*([^*]+)\*\*', r'\1', narration)
            narration = re.sub(r'\*([^*]+)\*', r'\1', narration)
            narration = narration.strip()
            if narration:
                segments.append(('narration', narration))

        # ëŒ€ì‚¬ ì¶”ì¶œ
        if match.re.pattern == emotion_dialogue_pattern:
            emotion = match.group(1)
            dialogue = match.group(2).strip()
            # ê°ì • íƒœê·¸ë¥¼ ëŒ€ì‚¬ ì•ì— ë¶™ì—¬ì„œ ë°˜í™˜ (í•„ìš” ì‹œ)
            full_dialogue = f"[{emotion}] \"{dialogue}\""
        else:
            full_dialogue = f"\"{match.group(1).strip()}\""

        segments.append(('dialogue', full_dialogue))

        last_end = match.end()

    # ë§ˆì§€ë§‰ ë‚˜ë ˆì´ì…˜
    remaining = text[last_end:].strip()
    if remaining:
        remaining = re.sub(r'\*\*([^*]+)\*\*', r'\1', remaining)
        remaining = re.sub(r'\*([^*]+)\*', r'\1', remaining)
        remaining = remaining.strip()
        if remaining:
            segments.append(('narration', remaining))

    # ì „ì²´ê°€ ëŒ€ì‚¬ë¡œë§Œ ì´ë£¨ì–´ì§„ ê²½ìš° fallback
    if not segments and '"' in text:
        dialogue = text.strip()
        dialogue = re.sub(r'\*\*([^*]+)\*\*', r'\1', dialogue)
        dialogue = re.sub(r'\*([^*]+)\*', r'\1', dialogue)
        segments.append(('dialogue', dialogue))
    elif not segments:
        # ëŒ€ì‚¬ ì—†ìœ¼ë©´ ì „ì²´ ë‚˜ë ˆì´ì…˜
        clean_text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text.strip())
        clean_text = re.sub(r'\*([^*]+)\*', r'\1', clean_text)
        if clean_text:
            segments.append(('narration', clean_text))

    return segments

def narrate_audio(llm, narration_text, narrator_voice_id):
    """
    ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ë¥¼ TTSë¡œ ë³€í™˜ (ë‚˜ë ˆì´í„° ìŒì„± ì‚¬ìš©)
    """
    language = llm.language

    if not narration_text or not narration_text.strip():
        logging.info("â­ï¸ ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤")
        return BytesIO()

    logging.info(f"ğŸ”Š ë‚˜ë ˆì´ì…˜ TTS ìƒì„± - voice_id: {narrator_voice_id}, language: {language}")

    audio_data = eleven_client.text_to_speech.convert(
        text=narration_text,
        voice_id=narrator_voice_id,
        language_code=language,
        model_id= "eleven_v3",
        voice_settings={
            "stability": 0.5,
            "similarity_boost": 0.5,
            "style": 0.0,
            "use_speaker_boost": True
        }
    )

    audio_buffer = BytesIO()
    for chunk in audio_data:
        if chunk:
            audio_buffer.write(chunk)
    audio_buffer.seek(0)
    return audio_buffer


def character_audio(llm, dialogue_text, character_voice_id):
    """
    ìºë¦­í„° ëŒ€ì‚¬ë¥¼ TTSë¡œ ë³€í™˜ (ìºë¦­í„° ìŒì„± ì‚¬ìš©)
    """
    language = llm.language

    if not dialogue_text or not dialogue_text.strip():
        logging.info("â­ï¸ ëŒ€ì‚¬ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤")
        return BytesIO()

    logging.info(f"ğŸ”Š ìºë¦­í„° ëŒ€ì‚¬ TTS ìƒì„± - voice_id: {character_voice_id}, language: {language}")

    audio_data = eleven_client.text_to_speech.convert(
        text=dialogue_text,
        voice_id=character_voice_id,
        language_code=language,
        model_id= "eleven_v3",

        voice_settings={
            "stability": 0.5,
            "similarity_boost": 0.5,
            "style": 0.0,
            "use_speaker_boost": True
        }
    )

    audio_buffer = BytesIO()
    for chunk in audio_data:
        if chunk:
            audio_buffer.write(chunk)
    audio_buffer.seek(0)
    return audio_buffer

def merge_audio(narration_buffer, dialogue_buffer):
    """
    ë‚˜ë ˆì´ì…˜ ì˜¤ë””ì˜¤ì™€ ëŒ€ì‚¬ ì˜¤ë””ì˜¤ë¥¼ ìˆœì„œëŒ€ë¡œ ë³‘í•© (ê¸°ì¡´ í•¨ìˆ˜ - í˜¸í™˜ì„± ìœ ì§€)
    - ë‚˜ë ˆì´ì…˜ì´ ë¨¼ì € ì¬ìƒë˜ê³ , ê·¸ ë‹¤ìŒ ëŒ€ì‚¬ê°€ ì¬ìƒë¨
    """
    if narration_buffer.getvalue() == b"":
        return dialogue_buffer
    if dialogue_buffer.getvalue() == b"":
        return narration_buffer

    narration_audio = AudioSegment.from_file(narration_buffer, format='mp3')
    dialogue_audio = AudioSegment.from_file(dialogue_buffer, format='mp3')

    # ë‚˜ë ˆì´ì…˜ â†’ ëŒ€ì‚¬ ìˆœì„œë¡œ ë³‘í•©
    merged = narration_audio + dialogue_audio

    output_buffer = BytesIO()
    merged.export(output_buffer, format="mp3")
    output_buffer.seek(0)

    return output_buffer


def generate_sequential_tts(llm, text, narrator_voice_id, character_voice_id):
    """
    í…ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ (ë‚˜ë ˆì´ì…˜â†’ëŒ€ì‚¬â†’ë‚˜ë ˆì´ì…˜â†’ëŒ€ì‚¬...) TTS ìƒì„±
    """
    segments = split_text_segments(text)

    if not segments:
        logging.warning("âš ï¸ ë¶„ë¦¬ëœ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
        return BytesIO()

    logging.info(f"ğŸ“ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ ê²°ê³¼: {len(segments)}ê°œ")
    for i, (seg_type, seg_text) in enumerate(segments):
        logging.info(f"  [{i+1}] {seg_type}: {seg_text[:30]}...")

    audio_segments = []
    language = llm.language

    for seg_type, seg_text in segments:
        if not seg_text.strip():
            continue

        voice_id = narrator_voice_id if seg_type == 'narration' else character_voice_id

        try:
            audio_data = eleven_client.text_to_speech.convert(
                text=seg_text,
                voice_id=voice_id,
                language_code=language,
                model_id="eleven_v3",
                voice_settings={
                    "stability": 0.5,
                    "similarity_boost": 0.5,
                    "style": 0.0,
                    "use_speaker_boost": True
                }
            )

            audio_buffer = BytesIO()
            for chunk in audio_data:
                if chunk:
                    audio_buffer.write(chunk)
            audio_buffer.seek(0)

            if audio_buffer.getvalue():
                audio_segment = AudioSegment.from_file(audio_buffer, format='mp3')
                audio_segments.append(audio_segment)
                logging.info(f"âœ… {seg_type} TTS ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logging.error(f"âŒ TTS ìƒì„± ì‹¤íŒ¨ ({seg_type}): {e}")
            continue

    if not audio_segments:
        logging.warning("âš ï¸ ìƒì„±ëœ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
        return BytesIO()

    # ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ì´ì— 0.5ì´ˆ ë¬´ìŒ ì¶”ê°€í•˜ë©° ë³‘í•©
    silence = AudioSegment.silent(duration=500)  # 500ms = 0.5ì´ˆ
    merged = audio_segments[0]
    for segment in audio_segments[1:]:
        merged = merged + silence + segment

    output_buffer = BytesIO()
    merged.export(output_buffer, format="mp3")
    output_buffer.seek(0)

    logging.info(f"ğŸµ ì´ {len(audio_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì™„ë£Œ (0.5ì´ˆ ë¬´ìŒ í¬í•¨)")
    return output_buffer


def process_and_generate_audio(llm, chat_history, user_text):
    """
    GPT/Grok ì‘ë‹µì„ ìƒì„±í•˜ê³ , ë‚˜ë ˆì´ì…˜/ëŒ€ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê°ê° ë‹¤ë¥¸ ìŒì„±ìœ¼ë¡œ TTS ìƒì„±
    """
    # 1. AI ì‘ë‹µ ìƒì„±
    if "grok" in llm.model.lower():
        raw_response = generate_response_grok(llm, chat_history, user_text)
    else:
        raw_response = generate_response_gpt(llm, chat_history, user_text)

    # 2. ë‚˜ë ˆì´ì…˜ê³¼ ëŒ€ì‚¬ ë¶„ë¦¬
    narration, dialogue = split_narration_dialogue(raw_response)

    logging.info(f"ğŸ“ ë¶„ë¦¬ëœ ë‚˜ë ˆì´ì…˜: {narration[:50]}..." if narration else "ğŸ“ ë‚˜ë ˆì´ì…˜ ì—†ìŒ")
    logging.info(f"ğŸ’¬ ë¶„ë¦¬ëœ ëŒ€ì‚¬: {dialogue[:50]}..." if dialogue else "ğŸ’¬ ëŒ€ì‚¬ ì—†ìŒ")

    # 3. ìŒì„± ID ì„¤ì • (Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©)
    # ê¸°ë³¸ ë‚˜ë ˆì´í„° ìŒì„± ID (ElevenLabs)
    DEFAULT_NARRATOR_VOICE = "LruHrtVF6PSyGItzMNHS"
    # ê¸°ë³¸ ìºë¦­í„° ìŒì„± ID (ElevenLabs)
    DEFAULT_CHARACTER_VOICE = "MClEFoImJXBTgLwdLI5n"

    narrator_voice = DEFAULT_NARRATOR_VOICE
    character_voice = DEFAULT_CHARACTER_VOICE

    if llm.narrator_voice and llm.narrator_voice.voice_id:
        narrator_voice = llm.narrator_voice.voice_id

    if llm.voice and llm.voice.voice_id:
        character_voice = llm.voice.voice_id

    logging.info(f"ğŸ™ï¸ ë‚˜ë ˆì´í„° ìŒì„± ID: {narrator_voice}")
    logging.info(f"ğŸ­ ìºë¦­í„° ìŒì„± ID: {character_voice}")

    # 4. TTS ìƒì„±
    narration_buffer = narrate_audio(llm, narration, narrator_voice)
    dialogue_buffer = character_audio(llm, dialogue, character_voice)

    # 5. ì˜¤ë””ì˜¤ ë³‘í•© ë° ë°˜í™˜
    final_audio = merge_audio(narration_buffer, dialogue_buffer)

    return HttpResponse(final_audio, content_type="audio/mpeg")